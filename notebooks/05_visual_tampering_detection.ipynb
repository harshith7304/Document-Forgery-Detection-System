{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 4:** Detect Visual Alteration Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model use Dice coeff.\n",
    "Separate the dataset into 3 repositories Train, Validate, and Testing with each having 2 repositories for the forged images and their respective masks.\n",
    "Training repository having 70% of images\n",
    "Validation repository having 15% of images\n",
    "Testing repository having 15% of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = keras.backend.flatten(y_true)\n",
    "    y_pred_f = keras.backend.flatten(y_pred)\n",
    "    intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (keras.backend.sum(y_true_f) + keras.backend.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = keras.losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred, weight=0.5):\n",
    "    \"\"\"\n",
    "    Calculate weighted binary cross-entropy and dice loss.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: True labels.\n",
    "    - y_pred: Predictions.\n",
    "    - weight: Weight for the positive class. The weight for the negative class will be 1.\n",
    "\n",
    "    Returns:\n",
    "    - Weighted loss value.\n",
    "    \"\"\"\n",
    "    # Calculate weighted binary cross-entropy loss\n",
    "    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    bce_weighted = bce * (y_true * weight + (1 - y_true) * (1 - weight))\n",
    "\n",
    "    # Calculate dice loss\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "\n",
    "    # Combine losses\n",
    "    loss = bce_weighted + dice\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_height = 512\n",
    "img_width = 512\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "image_datagen_train = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "\n",
    ")\n",
    "\n",
    "mask_datagen_train = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "\n",
    ")\n",
    "\n",
    "image_generator_train = image_datagen_train.flow_from_directory(\n",
    "    '/content/data/train/Forged',\n",
    "    class_mode=None,\n",
    "    color_mode='rgb',\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=2)\n",
    "\n",
    "mask_generator_train = mask_datagen_train.flow_from_directory(\n",
    "    '/content/data/train/Mask',\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None,\n",
    "    seed=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_datagen_valid = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "    )\n",
    "mask_datagen_valid = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "    )\n",
    "\n",
    "image_generator_valid = image_datagen_valid.flow_from_directory(\n",
    "    '/content/data/val/Forged',\n",
    "    class_mode=None,\n",
    "    color_mode='rgb',\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=2)\n",
    "\n",
    "mask_generator_valid = mask_datagen_valid.flow_from_directory(\n",
    "    '/content/data/val/Mask',\n",
    "    target_size=(img_height,img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=2)\n",
    "\n",
    "train_generator = zip(image_generator_train, mask_generator_train)\n",
    "validation_generator = zip(image_generator_valid, mask_generator_valid)\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), padding = 'same', activation = 'relu'))\n",
    "\n",
    "model.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'))\n",
    "\n",
    "model.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "\n",
    "model.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'))\n",
    "\n",
    "model.add(keras.layers.Conv2D(1, (1, 1), padding = 'same', activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=bce_dice_loss,\n",
    "    metrics=[dice_coeff, 'accuracy'],\n",
    ")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath='./logs/seg_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}_val_acc-{val_accuracy:.4f}.h5', #'./epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}_val_acc-{val_accuracy:.4f}.h5'\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                    mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "learning_rate_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.0000001)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "cal_b = [model_checkpoint]\n",
    "\n",
    "nb_epochs = 20\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=nb_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1,\n",
    "        steps_per_epoch=30//batch_size,\n",
    "        validation_steps=10//batch_size,\n",
    "        callbacks=cal_b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, len(history.history['accuracy'])+1), history.history['accuracy'])\n",
    "plt.plot(range(1, len(history.history['val_accuracy'])+1), history.history['val_accuracy'])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(history.history['loss'])+1), history.history['loss'])\n",
    "plt.plot(range(1, len(history.history['val_loss'])+1), history.history['val_loss'])\n",
    "plt.ylim(0, 2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_datagen_test = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "image_generator_test = image_datagen_test.flow_from_directory(\n",
    "    '/content/data/test/Forged',\n",
    "    class_mode=None,\n",
    "    color_mode='rgb',\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=2)\n",
    "mask_datagen_test = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "mask_generator_test = mask_datagen_test.flow_from_directory(\n",
    "    '/content/data/test/Mask',\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=2)\n",
    "# Evaluate the model\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(gen1.next(), gen2.next())\n",
    "\n",
    "test_generator = combine_generator(image_generator_test, mask_generator_test)\n",
    "steps = len(image_generator_test)\n",
    "loss,dice_coeff,accuracy = model.evaluate_generator(test_generator, steps=steps)\n",
    "\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test dice_coeff: {dice_coeff:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss: 0.4019\n",
    "\n",
    "Test iou_score: 0.8074\n",
    "\n",
    "Test dice_coeff: 0.8834\n",
    "\n",
    "Test accuracy: 0.4943"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
